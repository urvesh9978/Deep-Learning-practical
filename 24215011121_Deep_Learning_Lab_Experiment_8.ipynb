{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1) Task: Given a sequence of alphabets (with some missing values), use an RNN and a Bidirectional RNN model to predict the missing values in the sequence."
      ],
      "metadata": {
        "id": "9TCyV3ElBQbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Bidirectional, Dense, Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Character to Integer Mapping\n",
        "alphabet = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "char_to_int = {c: i+1 for i, c in enumerate(alphabet)}  # A=1, ..., Z=26\n",
        "char_to_int['_'] = 0  # Missing character\n",
        "int_to_char = {i: c for c, i in char_to_int.items()}\n",
        "\n",
        "# Step 2: Dataset - Original Word Sequences\n",
        "base_sequences = [\n",
        "    \"MACHINE\", \"LEARNING\", \"NETWORK\", \"SCIENCE\", \"DATA\",\n",
        "    \"COMPUTER\", \"ALGORITHM\", \"PROCESS\", \"SYSTEM\", \"MODEL\",\n",
        "]\n",
        "\n",
        "# Step 3: Introduce missing characters (with forced corruption if none missing)\n",
        "def introduce_missing(sequences, missing_prob=0.2):\n",
        "    corrupted_sequences = []\n",
        "    for seq in sequences:\n",
        "        seq_list = list(seq)\n",
        "        corrupted = False\n",
        "        for i in range(len(seq_list)):\n",
        "            if np.random.rand() < missing_prob:\n",
        "                seq_list[i] = '_'\n",
        "                corrupted = True\n",
        "        if not corrupted:\n",
        "            rand_index = np.random.randint(len(seq_list))\n",
        "            seq_list[rand_index] = '_'\n",
        "        corrupted_sequences.append(''.join(seq_list))\n",
        "    return corrupted_sequences\n",
        "\n",
        "corrupted_sequences = introduce_missing(base_sequences, missing_prob=0.1)\n",
        "print(\"Corrupted Sequences:\", corrupted_sequences)\n",
        "\n",
        "# Step 4: Convert sequences to integer format\n",
        "encoded_sequences = [[char_to_int[char] for char in seq] for seq in corrupted_sequences]\n",
        "\n",
        "# Step 5: Create supervised input-output pairs (X, y)\n",
        "X, y = [], []\n",
        "for orig, corrupted in zip(base_sequences, encoded_sequences):\n",
        "    for i, val in enumerate(corrupted):\n",
        "        if val == 0:\n",
        "            input_seq = corrupted.copy()\n",
        "            X.append(input_seq)\n",
        "            y.append(char_to_int[orig[i]])\n",
        "\n",
        "# Step 6: Padding only (NO normalization)\n",
        "max_len = max(len(seq) for seq in X)\n",
        "X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=max_len, padding='pre')\n",
        "y = np.array(y)\n",
        "\n",
        "# Step 7: Train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 8: Define RNN and BiRNN models using Embedding\n",
        "def build_rnn_model():\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim=28, output_dim=16, input_length=max_len),\n",
        "        SimpleRNN(150),\n",
        "        Dense(28, activation='softmax')  # 0–27 (0=_ missing, 1–26 = A–Z)\n",
        "    ])\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_birnn_model():\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim=28, output_dim=16, input_length=max_len),\n",
        "        Bidirectional(SimpleRNN(150)),\n",
        "        Dense(28, activation='softmax')\n",
        "    ])\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Step 9: Train models\n",
        "rnn = build_rnn_model()\n",
        "birnn = build_birnn_model()\n",
        "\n",
        "print(\"\\nTraining RNN...\")\n",
        "rnn.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=150, batch_size=16, verbose=0)\n",
        "\n",
        "print(\"\\nTraining Bidirectional RNN...\")\n",
        "birnn.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=150, batch_size=16, verbose=0)\n",
        "\n",
        "# Step 10: Prediction logic\n",
        "def fill_missing(model, seq):\n",
        "    chars = list(seq)\n",
        "    while '_' in chars:\n",
        "        int_seq = [char_to_int[c] if c != '_' else 0 for c in chars]\n",
        "        padded = tf.keras.preprocessing.sequence.pad_sequences([int_seq], maxlen=max_len, padding='pre')\n",
        "        pred = model.predict(padded, verbose=0)[0]\n",
        "        predicted_char = int_to_char[np.argmax(pred)]\n",
        "        missing_idx = chars.index('_')\n",
        "        chars[missing_idx] = predicted_char\n",
        "    return ''.join(chars)\n",
        "\n",
        "# Step 11: Test examples\n",
        "print(\"\\n--- Testing ---\")\n",
        "test_samples = corrupted_sequences[:3]\n",
        "new_test = \"_ACHINE\"\n",
        "test_samples.append(new_test)\n",
        "\n",
        "for seq in test_samples:\n",
        "    print(f\"Input : {seq}\")\n",
        "    print(f\"RNN Prediction Output:     {fill_missing(rnn, seq)}\")\n",
        "    print(f\"BiRNN Prediction Output:   {fill_missing(birnn, seq)}\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSU7S_GrBTOT",
        "outputId": "2d3c0b42-66f7-4f6f-b039-57157e0383b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corrupted Sequences: ['MACH_NE', 'LE_RNING', 'NETW_RK', 'S_IENCE', 'DA_A', '_OMP_TER', 'ALGO_ITHM', 'P_OCESS', 'SY_TEM', '_ODEL']\n",
            "\n",
            "Training RNN...\n",
            "\n",
            "Training Bidirectional RNN...\n",
            "\n",
            "--- Testing ---\n",
            "Input : MACH_NE\n",
            "RNN Prediction Output:     MACHTNE\n",
            "BiRNN Prediction Output:   MACHCNE\n",
            "\n",
            "Input : LE_RNING\n",
            "RNN Prediction Output:     LEARNING\n",
            "BiRNN Prediction Output:   LEARNING\n",
            "\n",
            "Input : NETW_RK\n",
            "RNN Prediction Output:     NETWORK\n",
            "BiRNN Prediction Output:   NETWORK\n",
            "\n",
            "Input : _ACHINE\n",
            "RNN Prediction Output:     TACHINE\n",
            "BiRNN Prediction Output:   CACHINE\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2) Predict the next word in a sentence using an RNN"
      ],
      "metadata": {
        "id": "LwE_PeIOBTmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Step 1: Dataset\n",
        "sentences = [\n",
        "    \"The cat sat on the mat.\",\n",
        "    \"The dog sat on the rug.\",\n",
        "    \"The bird flew in the sky.\",\n",
        "    \"The cat jumped over the fence.\",\n",
        "    \"The dog barked at the mailman.\",\n",
        "    \"The bird landed on the branch.\",\n",
        "    \"The cat chased a butterfly.\",\n",
        "    \"The dog dug a hole in the yard.\",\n",
        "    \"The bird sang from the rooftop.\"\n",
        "]\n",
        "\n",
        "# Step 2: Text Preprocessing\n",
        "# Tokenize the sentences\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index  # Dictionary mapping words to integers\n",
        "vocab_size = len(word_index) + 1  # +1 for padding (index 0)\n",
        "\n",
        "# Convert sentences to sequences of integers\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "\n",
        "# Create input-output pairs for training\n",
        "X_train, y_train = [], []\n",
        "for seq in sequences:\n",
        "    for i in range(1, len(seq)):\n",
        "        X_train.append(seq[:i])  # Previous words\n",
        "        y_train.append(seq[i])   # Next word\n",
        "\n",
        "# Pad sequences to ensure uniform length\n",
        "max_len = max(len(seq) for seq in sequences)  # Max sentence length\n",
        "X_train = pad_sequences(X_train, maxlen=max_len, padding='pre')\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "# Step 3: Build the RNN Model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=50, input_length=max_len),  # Word embeddings\n",
        "    SimpleRNN(150, return_sequences=False),  # Simple RNN layer\n",
        "    Dense(vocab_size, activation='softmax')  # Output layer for word prediction\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the Model\n",
        "print(\"Training the RNN model...\")\n",
        "model.fit(X_train, y_train, epochs=100, verbose=0)\n",
        "\n",
        "# Step 5: Prediction Function\n",
        "def predict_next_word(sentence):\n",
        "    # Tokenize and pad the input sentence\n",
        "    seq = tokenizer.texts_to_sequences([sentence])[0]\n",
        "    padded_seq = pad_sequences([seq], maxlen=max_len, padding='pre')\n",
        "\n",
        "    # Predict the next word\n",
        "    pred = model.predict(padded_seq, verbose=0)\n",
        "    pred_word_idx = np.argmax(pred)\n",
        "    return tokenizer.index_word.get(pred_word_idx, \"Unknown\")\n",
        "\n",
        "# Step 6: Test Prediction\n",
        "test_sentence_1 = \"The cat sat on\"\n",
        "test_sentence_2 = \"a dog barked\"\n",
        "predicted_word_1 = predict_next_word(test_sentence_1)\n",
        "predicted_word_2 = predict_next_word(test_sentence_2)\n",
        "print(f\"\\nInput Sentence: '{test_sentence_1}'\")\n",
        "print(f\"Predicted Next Word: '{predicted_word_1}'\")\n",
        "print(f\"\\nInput Sentence: '{test_sentence_2}'\")\n",
        "print(f\"Predicted Next Word: '{predicted_word_2}'\")\n",
        "\n",
        "# Optional: Show model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "FpMgEaIkBT9U",
        "outputId": "2a782efc-8b54-494c-f194-ab30c6a6092f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the RNN model...\n",
            "\n",
            "Input Sentence: 'The cat sat on'\n",
            "Predicted Next Word: 'the'\n",
            "\n",
            "Input Sentence: 'a dog barked'\n",
            "Predicted Next Word: 'at'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_11 (\u001b[38;5;33mEmbedding\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │           \u001b[38;5;34m1,450\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn_11 (\u001b[38;5;33mSimpleRNN\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)                 │          \u001b[38;5;34m30,150\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)                  │           \u001b[38;5;34m4,379\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,450</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">30,150</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,379</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m107,939\u001b[0m (421.64 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">107,939</span> (421.64 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m35,979\u001b[0m (140.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,979</span> (140.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m71,960\u001b[0m (281.10 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">71,960</span> (281.10 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3) Build an RNN-based sequence generator to predict the next note in a series of Indian classical music notes. Begin with the basic scale (Sa, Re, Ga, Ma, Pa, Dha, Ni, Sha), generate training sequences, and convert the notes to numerical form for model input. Train the RNN to learn note transitions and extend the model to generate melodic sequences for ragas like Bhairav, Bhopali, and Bageshree"
      ],
      "metadata": {
        "id": "PzcC9GYULoq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, random\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "ragas = {\n",
        "    'basic':    ['Sa', 'Re', 'Ga', 'Ma', 'Pa', 'Dha', 'Ni', 'Sha'],\n",
        "    'bhopali':  ['Sa', 'Re', 'Ga', 'Pa', 'Dha', 'Sha'],\n",
        "    'bageshree':['Sa', 'Re', 'Ga', 'Ma', 'Dha', 'Ni', 'Sha'],\n",
        "    'bhairav':  ['Sa', 'Re♭', 'Ga', 'Ma', 'Pa', 'Dha♭', 'Ni', 'Sha']\n",
        "}\n",
        "\n",
        "def generate_sequences(notes, count=100, length=5):\n",
        "    return [random.choices(notes, k=length) for _ in range(count)]\n",
        "\n",
        "def prepare_data(sequences, notes):\n",
        "    note_to_idx = {note: i for i, note in enumerate(notes)}\n",
        "    idx_to_note = {i: note for note, i in note_to_idx.items()}\n",
        "    X, y = [], []\n",
        "    for seq in sequences:\n",
        "        for i in range(1, len(seq)):\n",
        "            X.append([note_to_idx[n] for n in seq[:i]])\n",
        "            y.append(note_to_idx[seq[i]])\n",
        "    max_len = max(len(s) for s in X)\n",
        "    X = pad_sequences(X, maxlen=max_len)\n",
        "    y = to_categorical(y, num_classes=len(notes))\n",
        "    return X, y, note_to_idx, idx_to_note, max_len\n",
        "\n",
        "def build_model(vocab_size):\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size, 10),\n",
        "        SimpleRNN(64),\n",
        "        Dense(vocab_size, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def train_and_generate(raga_name, notes):\n",
        "    print(f\"\\nRaga: {raga_name.upper()}\")\n",
        "    sequences = generate_sequences(notes)\n",
        "    X, y, n2i, i2n, maxlen = prepare_data(sequences, notes)\n",
        "    model = build_model(len(notes))\n",
        "    model.fit(X, y, epochs=30, verbose=0)\n",
        "\n",
        "    # Fixed seed input\n",
        "    seed = ['Sha', 'Ga', 'Sa']\n",
        "    print(\"Seed:\", seed)\n",
        "    generated = seed.copy()\n",
        "\n",
        "    for _ in range(5):  # generate next 5 notes only\n",
        "        encoded = [n2i[n] for n in generated[-maxlen:]]\n",
        "        padded = pad_sequences([encoded], maxlen=maxlen)\n",
        "        pred_idx = np.argmax(model.predict(padded, verbose=0))\n",
        "        generated.append(i2n[pred_idx])\n",
        "\n",
        "    print(\"Next 5 Notes:\", generated[len(seed):])\n",
        "\n",
        "for raga in ragas:\n",
        "    train_and_generate(raga, ragas[raga])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ME07O-6ILri0",
        "outputId": "2de2c9c2-2750-4fc1-82c8-15a260fc5910"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Raga: BASIC\n",
            "Seed: ['Sha', 'Ga', 'Sa']\n",
            "Next 5 Notes: ['Pa', 'Re', 'Pa', 'Sha', 'Ga']\n",
            "\n",
            "Raga: BHOPALI\n",
            "Seed: ['Sha', 'Ga', 'Sa']\n",
            "Next 5 Notes: ['Pa', 'Re', 'Sha', 'Re', 'Pa']\n",
            "\n",
            "Raga: BAGESHREE\n",
            "Seed: ['Sha', 'Ga', 'Sa']\n",
            "Next 5 Notes: ['Ma', 'Dha', 'Sa', 'Re', 'Dha']\n",
            "\n",
            "Raga: BHAIRAV\n",
            "Seed: ['Sha', 'Ga', 'Sa']\n",
            "Next 5 Notes: ['Re♭', 'Dha♭', 'Re♭', 'Ga', 'Ga']\n"
          ]
        }
      ]
    }
  ]
}